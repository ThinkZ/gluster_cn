体系结构
============

# # # 类型的卷

卷是砖和大部分的 gluster 文件系统集合
操作发生在卷上。Gluster 文件系统支持不同

基于需求的卷的类型。一些卷是好的

扩展存储大小，一些为改善性能，一些为两个。

1.* * 分布式 Glusterfs 卷 * *-这是默认 glusterfs
卷，即，如果你不指定的类型创建卷时
卷，默认选项是创建一个分布式的卷。
在这里，文件分布在卷中的各种砖。所以 file1

可能存储只能在 brick1 或 brick2，但不是上两个。因此，那里是

没有数据冗余。这种存储卷的目的是向容易 & 便宜

扩展卷的大小。但是这也意味着砖失败将

率先完成丢失的数据，另一个必须依靠基础
硬件的数据丢失防护。

![] distributed_volume() https://cloud.githubusercontent.com/assets/10970993/7412364/ac0a300c-ef5f-11e4-8599-e7d06de1165c.png


* 分布式卷 *

创建一个分布式的卷

* * gluster 卷创建新 VOLNAME [运输 [tcp | rdma | tcp，rdma]]
新砖......* *

* * 为示例 * * 来创建分布式的卷，四个存储服务器
使用 TCP。

gluster 卷创建测试卷 server1: / exp1 server2: / exp2 server3: / exp3 server4: / exp4
创建测试卷已成功
请开始访问数据卷

若要显示卷信息

#gluster 卷信息
卷名︰ 测试卷
类型︰ 分发
状态︰ 创建
砖的数目︰ 4
传输类型︰ tcp
砖头︰
Brick1: server1: / exp1
Brick2: server2: / exp2
Brick3: server3: / exp3
Brick4: server4: / exp4

2.* * 复制 Glusterfs 卷 * *-在我们克服这卷
在分布式卷所面临的数据丢失问题。这里确切的副本

数据被按所有砖块。在复制副本的数量

在创建卷时，可以由客户端决定卷。所以我们需要

有至少两个砖块 2 副本或最小值与创建卷
三个砖块来创建 3 副本的卷。一个主要优点

这种体积是，即使一个砖失败数据仍然可以被
访问从其复制的砖。为更好地使用这种卷

可靠性和数据冗余。

![] replicated_volume() https://cloud.githubusercontent.com/assets/10970993/7412379/d75272a6-ef5f-11e4-869a-c355e8505747.png


* 复制卷 *

创建复制的卷

* * gluster 卷创建新 VOLNAME [副本计数] [运输 [tcp |
rdma |tcp rdma]] 新砖......* *


* * 为示例 * *，来创建带有两个存储服务器复制的卷︰

# gluster 卷创建测试卷副本 2 运输 tcp server1: / exp1 server2: / exp2
创建测试卷已成功
请开始访问数据卷

3.* * 分布式复制 Glusterfs 卷 * *-在这卷文件
分布在复制集的砖。砖的数目

必须复制副本计数的倍数。也的顺序我们

指定砖事宜，由于相邻砖成为每个副本
其他。这种类型的卷使用时高由于数据的可用性

冗余和扩展存储是必需的。所以，如果有八

砖和副本数 2 然后首先两砖成为的副本
对方那么两下，等等。此卷被指作为 4 × 2。

同样如果有八个砖和副本都算 4 然后四
砖成为彼此的副本和我们表示此卷为 2 x 4
卷。

![] distributed_replicated_volume() https://cloud.githubusercontent.com/assets/10970993/7412402/23a17eae-ef60-11e4-8813-a40a2384c5c2.png


* 分布式复制卷 *

创建分布式复制的卷︰

* * \ # gluster 卷创建
新 VOLNAME [副本计数] [运输 [tcp | rdma | tcp，rdma]]
新砖......* *

* * 为示例 * *，四个节点的分布式与双向 （复制） 的卷
镜像︰

# gluster 卷创建测试卷副本 2 运输 tcp server1: / exp1 server2: / exp2 server3: / exp3 server4: / exp4
创建测试卷已成功
请开始访问数据卷

4.* * 条纹 Glusterfs 卷 * *-考虑被存储在一个大的文件
这在同一时间频繁地访问多个客户端的砖。
这会对单砖造成负荷过大，会减少
性能。带区卷中的数据存储在砖后

将其划分为不同的条纹。如此大的文件将被划分

成小块 （等于砖的体积数） 和
每个数据块存储在一块砖。现在，负载分布和

文件可以更快地回迁，但不提供数据冗余。

![] striped_volume() https://cloud.githubusercontent.com/assets/10970993/7412387/f411fa56-ef5f-11e4-8e78-a0896a47625a.png


* 带区卷 *

创建带区的卷

gluster 卷创建新 VOLNAME [条纹计数] [运输 [tcp | dma | tcp，rdma]] 新砖......

* * 为示例 * *，在两个存储服务器之间创建带区的卷︰

# gluster 卷创建测试卷条纹 2 运输 tcp server1: / exp1 server2: / exp2
创建测试卷已成功
请开始访问数据卷

5.* * 分布式条纹 Glusterfs 卷 * *-这是类似于
只是现在可以分发条纹条纹 Glusterfs 卷
跨更多数量的砖。然而多少砖必须

条带数的倍数。所以，如果我们想要增加卷的大小

我们必须添加砖块在条带数的倍数。

![] distributed_striped_volume() https://cloud.githubusercontent.com/assets/10970993/7412394/0ce267d2-ef60-11e4-9959-43465a2a25f7.png


* 分布式的带区卷 *

创建分布式的带区的卷︰

* * gluster 卷创建新 VOLNAME [条纹计数] [运输 [tcp |
rdma |tcp rdma]] 新砖......* *


例如，要创建分布式的带区的卷八
存储服务器︰

# gluster 卷创建测试卷条纹 4 运输 tcp
server1: / exp1 server2: / exp2 server3: / exp3 server4: / exp4 server5: / exp5 server6: / exp6 server7: / exp7 server8: / exp8
创建测试卷已成功
请开始访问的数据量。

# # # 保险丝

GlusterFS 是用户空间的文件系统。这是所作的决定

GlusterFS 最初是作为模块进入 linux 内核的开发人员
是一个非常漫长而艰难的过程。

被一个用户空间的文件系统，与内核 VFS，GlusterFS 进行交互
使用的保险丝 （在用户空间的文件系统）。对于很长的时间，

执行一个用户空间的文件系统被认为不可能。保险丝

是为此开发作为一种解决方案。导火索是一个内核模块，

支持内核 VFS 和非特权用户之间的互动
应用程序，它有可以从用户空间访问的 API。
使用此 API，任何类型的文件系统可以编写使用几乎任何
你喜欢有很多绑定之间保险丝和其他的语言
语言。

![] fuse_structure() https://cloud.githubusercontent.com/assets/10970993/7412530/67a544ae-ef61-11e4-8979-97dad4031a81.png


* FUSE.* 结构示意图

这展示文件系统编译以创建的"你好世界"
"你好"的二进制文件。这被执行与文件系统挂载点 /tmp/保险丝。

然后用户发出命令 ls-l 上装载点 /tmp/保险丝。这

命令到达 VFS 通过 glibc 和因为装载 /tmp/保险丝对应
到一个保险丝基于文件系统，VFS 经过它到保险丝模块。保险丝

内核模块后接触实际文件系统二进制"你好"
通过传递 glibc 和保险丝图书馆在 userspace(libfuse) 中。结果

通过"你好"通过相同的路径返回，并达到 ls-l
命令。

FUSE 内核模块和保险丝之间的通信
library(libfuse) 是一个特殊的文件描述符由获得通过
打开 /dev/fuse。此文件可以打开多次，和

得到的文件描述符传递给装载系统调用，以匹配
描述符与挂载的文件系统。

-[更多关于用户空间
文件系统] (http://www.linux-mag.com/id/7814/)
-[保险丝参考] (http://fuse.sourceforge.net/)

# # # 翻译

* * 翻译"笔译员"* *:

-翻译转换为请求从用户存储的请求。

* 一对一、 一对多、 一个到零 （例如缓存）

![翻译]() https://cloud.githubusercontent.com/assets/10970993/7412595/fd46c492-ef61-11e4-8f49-61dbd15b9695.png


-翻译可以修改请求通过的路上︰

* 一个请求将类型转换为另一种 （请求在传输过程中译者之一）
* 修改路径，标志，甚至数据 （例如加密）

— — 译者可以拦截或阻止的请求。（如访问

控制）

-或生成新请求 （例如预取）

* * 如何做翻译工作？ * *

-共享对象
-根据 'volfile' 动态加载

* dlopen/dlsync
* 设置指向父母 / 孩子们
* 调用 init （构造函数）
* 调用 IO 函数通过主席之友。

-规范验证 / 传递选项等。
-译者 （自 GlusterFS 3.1) 配置管理
通过 gluster 命令行界面 (cli)，所以你不需要
要知道在一起图译者的排列顺序。

# # # 类型的翻译

已知的翻译与它们的当前状态的列表。

转换器类型 |功能用途

:---------------:| --------------------------------------------------------------------------------------------------------------
存储 |最低的电平转换器，储存和从本地文件系统访问数据。

调试 |提供接口和统计数据的错误和调试。

群集 |因为它涉及到向写入和读取从砖及节点处理分配和复制数据。

加密 |上飞解密的存储数据的扩展翻译。

协议 |客户端/服务器通信协议的扩展翻译。

性能 |调优译者用于调整的工作量和 I/O 配置文件。

绑定 |添加可扩展性，例如由杰夫达西扩展 API 交互与 GlusterFS 写 Python 接口。

系统 |系统访问翻译，例如与文件系统访问控制的接口。

调度程序 |确定如何在群集系统中分发新的写入操作的 I/O 调度策略。

功能 |添加额外的功能，如配额、 筛选器、 锁等。


默认值 / 一般译者在卷文件的层次结构︰

![] translator_h() https://cloud.githubusercontent.com/assets/628699/9002815/07d93ce4-3771-11e5-8bda-9018871aa6fb.png


挂接在一起执行一个函数的所有笔译员被称为
图。笔译员左一整套包括的 * * 客户端-堆栈 * *。的

权集的翻译包括的 * * 服务器-堆栈 * *。

* * Glusterfs 翻译可以分为很多类，但
分为两种重要-群集和性能译者: * *

最重要的内容之一和第一次翻译之前数据的请求了
去是 * * 保险丝译者 * * 所属于的类别
* * 山译者 * *。

1.* * 群集译者 * *:

* DHT(Distributed Hash Table)

* AFR(Automatic File Replication)

1.* * 性能译者 * *:

* io 缓存

* io 线程

* md 缓存

* O B （打开隐藏）

* QR （快速阅读）

* r 一 （预读）

* w-b （后写）

其他 * * 功能翻译 * * 包括︰

* 更新日志

* 锁-GlusterFS 已锁译者提供以下内部锁定操作
  called `inodelk`, `entrylk`,
由空燃比，其中用于实现同步对文件或相互冲突的目录操作。

* 标记

* 配额

* * 调试译者 * *

* 跟踪-跟踪译者之间通信的过程中生成的错误日志。

* io 统计

# # # DHT(Distributed Hash Table) 翻译

* * 什么是双氢睾酮？ * *

DHT 是如何 GlusterFS 聚合能力的真正核心和
跨多个服务器的性能。它的职责是每个

上确切地之一其 subvolumes — — 不同于任何复制的文件 （其中
对所有其 subvolumes 的地方拷贝） 或条带化 （这地方件
上的所有其 subvolumes）。这是一个路由的功能，不分裂或

复制。

* * 如何 DHT 工程 * * 吗？

DHT 的基本方法是一致性哈希。每一个子宗卷

（砖） 分配一个 32 位哈希空间范围覆盖
与无孔或重叠的整个范围。然后还指派给每个文件

在相同的空间，由其名称的哈希值。恰好一个砖将

已分配的范围，包括文件的哈希值，所以该文件
"应该"的那块砖头。然而，有很多情况下在哪里，

不会的情况下，例如当砖套 (和因此
工作分配范围的范围） 已更改，因为在创建该文件，或
当砖是满的。许多复杂的 DHT 牵涉到

这些特殊情况，我们会在稍后讨论。

当你 open （） 的文件，分发译者给一块
要查找您的文件，文件名称信息。若要确定位置，

文件是，译者通过哈希算法运行文件名称
以该文件的名称变成了一些。

* * 哈希值分配 DHT * * 的几点意见︰

1.分配到砖的哈希值范围由扩展
属性存储在目录上，因此分布是
特定的目录。
2.一致性哈希是通常被认为的散列绕了一圈，
但在 GlusterFS 更线性化。没有必要地"环绕"

在零，因为那里是一种解脱 （介于一砖
和另一个人的） 为零。
3.如果缺少一块砖，则哈希空间上将一个洞了。即使

糟糕的是，如果哈希值范围重新分配砖处于脱机状态，有些时
新的范围可能会重叠的 （现在已经过时） 的范围
创建有点困惑在哪里的那块砖头上存储的文件
应该是。

# # # AFR(Automatic File Replication) 翻译

自动文件复制 (AFR) 在 GlusterFS 译者使用
扩展属性来跟踪文件操作。它是

负责对面的砖块复制数据。

# # # 的空燃比的责任

其职责包括以下内容︰

1.保持复制一致性 （即数据这两种砖上
应该是一样的即使在情况下那里有行动
发生在同一目录中从多个并行
应用程序/装载点，只要在副本中的所有砖块都设置
是了）。
2.提供恢复如果发生故障，只要数据的方法
有至少一个砖具有正确的数据。
3.服务为读/stat/readdir 等最新数据。

# # # 土力工程处复制

土力工程处复制提供跨数据异步的复制
地理位置不同的位置，并介绍了在 Glusterfs 3.2。
它主要从事跨广域网和用于复制整个卷
与不同的空燃比是群集内复制。这主要是有用的

整个数据用于灾难恢复的备份。

土力工程处复制使用一种主从模式，藉以复制发生
之间 * * 主 * *-GlusterFS 卷和 * * 的奴隶 * *-可
本地目录或 GlusterFS 卷。奴隶 (本地目录或

卷是使用访问 SSH 隧道）。

土力工程处复制提供增量复制服务在本地
局域网 (Lan)、 广域网 (Wan) 和跨越
互联网。

* * 通过 LAN * * 土力工程处复制

您可以配置土力工程处复制到镜像数据在本地区域
网络。

![geo-] rep_lan() https://cloud.githubusercontent.com/assets/10970993/7412281/a542e724-ef5e-11e4-8207-9e018c1e9304.png


* * 上湾的土力工程处复制 * *

您可以配置 Geo-复制在较宽的区域复制数据
网络。

![geo-] rep_wan() https://cloud.githubusercontent.com/assets/10970993/7412292/c3816f76-ef5e-11e4-8daa-271f6efa1f58.png


* * 在互联网 * * 土力工程处复制

您可以配置土力工程处复制到镜像数据在互联网上。

![geo-] rep03_internet() https://cloud.githubusercontent.com/assets/10970993/7412305/d8660050-ef5e-11e4-9d1b-54369fb1e43f.png


* * 多站点级联 Geo-复制 * *

您可以配置土力工程处复制到镜像数据级联的方式
跨多个站点。

![geo-] rep04_cascading() https://cloud.githubusercontent.com/assets/10970993/7412320/05e131bc-ef5f-11e4-8580-a4dc592148ff.png


异步复制数据时有两个主要方面︰

1.* * 更改检测 * *-其中包括必要的文件操作
详细信息。有两种方法来同步检测到的更改︰


一、 更新历史-更新日志是记录必要的翻译
主席之友所发生的细节。这些更改可以在二进制文件中写入

格式或 ASCII。有三个类别，每个类别都代表

通过一种特定的更新日志格式。所有三种类型的类别

单个日志文件中记录。

* * 输入 * *-create （）、 mkdir()、 mknod()、 symlink()、 link()、 重新命名 （），
作用是:、 rmdir()

* * 数据 * *-write （）、 writev()、 truncate()、 ftruncate()

* * 元 * *-setattr()，fsetattr()，setxattr()，fsetxattr()，
removexattr()、 fremovexattr()

为了记录的操作和实体类型术，一种类型
使用标识符。通常情况下，操作的实体

执行将识别出的路径名，但我们选择使用
GlusterFS 的内部文件标识符 (GFID) 相反 （作为 GlusterFS 支持
GFID 根据后端和路径名字段，并不一定有效，
其他原因的范围，为此本文档）。因此，

为三种类型记录的格式可以是操作的
总结如下︰

条目-GFID + FOP + 模式 + UID + GID + PARGFID/输出书名及 [PARGFID/输出书名及]

元-GFID 的文件

数据-GFID 的文件

GFID 的是类似于 inode。数据和元 fops 记录的 GFID

实体的执行操作，从而记录，
有人在 inode 上的数据/元数据更改。主席之友条目记录在

最低一组六个或七个记录 （根据的类型
操作），这是不足以确定哪种类型的操作
经历了实体。通常此记录包含实体的 GFID

文件操作 （这是 [一个枚举值的整数的类型
这用于 Glusterfs]） 和父 GFID 和 basename
(类似于父 inode 和 basename)。

更新日志文件是在特定的时间间隔后翻了。我们然后

处理对文件执行操作一样将其转换为
可以理解人类可读的格式，保持的私有副本
更新日志等。图书馆然后消耗这些日志和服务

应用程序请求。

二.Xsync-标记翻译维护扩展的属性"xtime"
每个文件和目录。每当任何更新发生时它会更新

xtime 属性该文件和它的所有祖先。这样的变化是

从节点 （在那里已经发生了变化） 传播到所有的方式
根。

![geo 复制同步]() https://cloud.githubusercontent.com/assets/10970993/7412646/824add4a-ef62-11e4-9a0b-5cc270be6a10.png


考虑上述目录的树状结构。在时间 T1 大师和

奴隶被同步。

![geo-复制-异步]() https://cloud.githubusercontent.com/assets/10970993/7412653/93b04e30-ef62-11e4-9ab1-e5cc57eb0db5.jpg


在时间 T2 File2 新文件的创建。这将触发 xtime

从高达 File2 到标记 （其中 xtime 当前时间戳)
根，即，File2、 Dir3、 Dir1 和最后所有将的 Dir0 xtime
更新。

土力工程处复制守护进程进行爬网基于条件的文件系统
那 xtime(master) \ > xtime(slave)。因此在我们的示例中它将爬

仅左边的部分的以来的右侧部分的目录结构
目录结构仍然具有相等的时间戳。虽然对进行爬网

算法是快速我们仍然需要爬好部分目录
结构。

2.* * 复制 * *-我们使用 rsync 进行数据复制。Rsync 是

外部的实用程序，它将计算比较两个文件和
从来源来同步发送这种差异。

# # # 整体工作的 GlusterFS

只要 GlusterFS 安装在一个服务器节点，gluster 管理
将创建 daemon(glusterd) 二进制。应运行此守护进程

在群集中的所有参与节点。后开始 glusterd，

可以创建受信任的服务器 pool(TSP)
组成的所有存储服务器节点 （TSP 可以包含单个甚至
节点）。现在可以作为创建砖是存储的基本单位

导出这些服务器中的目录。任意数量的从这个 TSP 砖

可以凑成一卷。

一旦创建了一个卷，
glusterfsd 进程开始运行在每个参与的砖。
此配置文件称为卷文件将
在 /var/lib/glusterd/vols 中产生 /。将配置

对应每个砖卷中的文件。这将包含所有

有关特定的那块砖头的详细信息。所需的配置文件

此外将创建一个客户端进程。现在我们的文件系统是准备

使用。我们可以很容易，如下所示将这个卷装入在客户机上

并使用它像我们使用本地存储区︰

    mount.glusterfs `<IP or hostname>`:`<volume_name>` `<mount_point>

IP 或主机名可以是任何节点中的受信任的服务器池
这创建了所需的卷。

当我们安装在客户端，客户端 glusterfs 进程中卷
与服务器的 glusterd 进程通信。服务器 glusterd 进程

发送一个包含列表中客户端的配置文件 （vol 文件）
笔译员和另一个包含每个砖的信息
卷的帮助下，客户端 glusterfs 进程现在可以
直接与每个砖 glusterfsd 进程通信。安装程序

现在完成，该卷现准备客户端的服务。

![] overallprocess() https://cloud.githubusercontent.com/assets/10970993/7412664/a9aaaece-ef62-11e4-8c87-75d8e7157739.png


当一个系统调用 （文件操作或 Fop） 稿由客户端在
挂载的文件系统，VFS （识别的文件系统类型
glusterfs) 将向 FUSE 内核模块发送请求。保险丝

内核模块反过来将发送给 GlusterFS 的用户空间中
客户端节点通过 /dev/保险丝 （这已被部分所述保险丝）。
客户端上的 GlusterFS 进程包括堆栈的翻译
要求客户端配置中定义的翻译
通过存储服务器 glusterd 进程发送文件 （vol 文件）。第一次

这些译者中被保险丝译者组成的
保险丝 library(libfuse)。每个翻译人员有相应的功能

对每个文件操作或 fop 支持由 glusterfs。该请求将

打中每个翻译人员对应的函数。主要客户

翻译人员包括︰

熔断器翻译
-双氢睾酮 DHT 译者翻译将请求映射到正确的砖
它包含的文件或目录所需。
-空燃比译者 — — 它接收请求从以前的翻译
和如果卷类型是复制，它重复请求和
把它交给协议客户端副本翻译。
-协议客户端翻译-协议客户端译者是最后一次
在客户端译者堆栈。此翻译分为

多个线程，一个用于每个砖的体积。这将

直接沟通与 glusterfsd 的每一块砖。

在存储服务器节点，其中包含需要，请求中的砖头
再次经过一系列的称为服务器译者的翻译
主要的是︰

-协议服务器翻译
-POSIX 翻译

该请求将最终达到 VFS，然后将与沟通
底层的本机文件系统。响应将沿着相同的路径。

